{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Evaluation\n",
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "from evo.core.trajectory import PoseTrajectory3D\n",
    "from evo.tools import file_interface\n",
    "import os\n",
    "\n",
    "from evo.core import sync\n",
    "from evo.core import metrics\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def read_ref_to_tum(path_ref, path_stamps):\n",
    "    stamps = np.loadtxt(path_stamps, dtype = np.float64)\n",
    "\n",
    "    with open(path_ref, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    xyz = np.zeros((len(lines), 3), dtype = np.float64)\n",
    "    quat = np.zeros((len(lines), 4), dtype = np.float64)\n",
    "\n",
    "    for i , line in enumerate(lines):\n",
    "        Tcw = np.array(list(map(float, line.split()))).reshape(4, 4)\n",
    "        # Tcw[:3, 1] *= -1\n",
    "        # Tcw[:3, 2] *= -1\n",
    "        \n",
    "        xyz[i, :] = Tcw[0:3, 3]\n",
    "        \n",
    "        rot = R.from_matrix(Tcw[0:3, 0:3])\n",
    "        quat[i, :] = rot.as_quat()\n",
    "    \n",
    "    return PoseTrajectory3D(xyz, quat, stamps)\n",
    "\n",
    "# load ref\n",
    "def load_traj_ref_dict(dir, path_stamps): \n",
    "    traj_ref_dict = {}\n",
    "    for filename in os.listdir(dir): \n",
    "        traj_ref_dict[filename[:-4]] = read_ref_to_tum(os.path.join(dir, filename), path_stamps)\n",
    "    return traj_ref_dict\n",
    "\n",
    "# compute stats of one given experiment\n",
    "def compute_single_stat(seq, method, k, key, dir_est, traj_ref_dict, max_diff):\n",
    "    line = [seq, method, k, 0, 1, 1, -1, -1]\n",
    "\n",
    "    abs_path = os.path.join(dir_est, key + '.txt')\n",
    "    if not os.path.isfile(abs_path): \n",
    "        return line \n",
    "    if not os.path.getsize(abs_path):\n",
    "        return line\n",
    "\n",
    "    traj_est = file_interface.read_tum_trajectory_file(abs_path)\n",
    "    traj_ref = traj_ref_dict[seq]\n",
    "    if traj_est.num_poses < 3:\n",
    "        return line\n",
    "    path_length_ref = traj_ref.path_length\n",
    "    \n",
    "    # synchronize, align and scale\n",
    "    traj_ref, traj_est_aligned = sync.associate_trajectories(traj_ref, traj_est, max_diff)\n",
    "    traj_est_aligned.align(traj_ref, correct_scale=True, correct_only_scale=False)\n",
    "\n",
    "    # create metric relation and data\n",
    "    pose_relation = metrics.PoseRelation.translation_part\n",
    "    data = (traj_ref, traj_est_aligned)\n",
    "\n",
    "    # process APE\n",
    "    ape_metric = metrics.APE(pose_relation)\n",
    "    ape_metric.process_data(data)\n",
    "\n",
    "    ape_stat = ape_metric.get_statistic(metrics.StatisticsType.rmse)\n",
    "    line[3] = traj_est_aligned.path_length / path_length_ref\n",
    "    line[4] = ape_stat\n",
    "\n",
    "    # RPE\n",
    "    # synchronize, align and scale\n",
    "    traj_ref, traj_est_rpe = sync.associate_trajectories(traj_ref, traj_est, max_diff)\n",
    "\n",
    "    pose_relation = metrics.PoseRelation.rotation_angle_rad\n",
    "\n",
    "    # normal mode\n",
    "    delta = 1\n",
    "\n",
    "    # all pairs mode\n",
    "    all_pairs = False  # activate\n",
    "    data = (traj_ref, traj_est_rpe)\n",
    "\n",
    "    rpe_metric = metrics.RPE(pose_relation=pose_relation, delta=delta, all_pairs=all_pairs)\n",
    "    rpe_metric.process_data(data)\n",
    "\n",
    "    rpe_stat = rpe_metric.get_statistic(metrics.StatisticsType.rmse)\n",
    "    line[5] = rpe_stat\n",
    "\n",
    "\n",
    "    abs_path_feats = os.path.join(dir_est, 'keypoints', key + '_feats.txt')\n",
    "    if not os.path.isfile(abs_path_feats): \n",
    "        return line \n",
    "    if not os.path.getsize(abs_path_feats):\n",
    "        return line\n",
    "    \n",
    "    with open(abs_path_feats, 'r') as f: \n",
    "        ll = [int(l) for l in f]\n",
    "        if len(ll) == 2:\n",
    "            line[6:] = ll\n",
    "    \n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference (grund truth) preparation\n",
    "\n",
    "dir_ref = \"/media/huanglab/HuangLab10TB/slam_team/dataset/Replica/ref/\"\n",
    "path_stamps = \"/media/huanglab/HuangLab10TB/slam_team/dataset/Replica/timestamp_20hz.txt\"\n",
    "traj_ref_dict = load_traj_ref_dict(dir_ref, path_stamps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image perturbation (static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stats(dir_est, traj_ref_dict, max_diff = 0.01): \n",
    "    # Save results, with list of ALL settings regardless of having results\n",
    "    data_table = []\n",
    "\n",
    "    methods = [\"motion_blur\", \"defocus_blur\", \"gaussian_blur\", \"glass_blur\",\n",
    "            \"gaussian_noise\", \"shot_noise\", \"impulse_noise\", \"speckle_noise\", \n",
    "            \"fog\", \"frost\", \"snow\", \"spatter\",\n",
    "            \"brightness\", \"contrast\", \"jpeg_compression\", \"pixelate\"]\n",
    "\n",
    "    for method in methods: \n",
    "        for k in range(1, 6, 2): \n",
    "            # office \n",
    "            for n in range(5):\n",
    "                seq = \"office\" + str(n)\n",
    "                key = '_'.join([seq, method, str(k)])\n",
    "                line = compute_single_stat(seq, method, k, key, dir_est, traj_ref_dict, max_diff)\n",
    "                data_table.append(line)\n",
    "            \n",
    "            # room \n",
    "            for n in range(3):\n",
    "                seq = \"room\" + str(n)\n",
    "                key = '_'.join([seq, method, str(k)])\n",
    "                line = compute_single_stat(seq, method, k, key, dir_est, traj_ref_dict, max_diff)\n",
    "                data_table.append(line)\n",
    "    # None\n",
    "    # office\n",
    "    for n in range(5):\n",
    "        seq = \"office\" + str(n)\n",
    "        key = '_'.join([seq, 'none', '0'])\n",
    "        line = compute_single_stat(seq, 'none', '0', key, dir_est, traj_ref_dict, max_diff)\n",
    "        data_table.append(line)\n",
    "\n",
    "    # room \n",
    "    for n in range(3):\n",
    "        seq = \"room\" + str(n)\n",
    "        key = '_'.join([seq, 'none', '0'])\n",
    "        line = compute_single_stat(seq, 'none', '0', key, dir_est, traj_ref_dict, max_diff)\n",
    "        data_table.append(line)\n",
    "    \n",
    "    return data_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_est = \"/media/huanglab/HuangLab10TB/slam_team/sibo/results_replica/rgbd/rgbd1_image_perturbation/\"\n",
    "data_table = compute_stats(dir_est, traj_ref_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       APE          \n",
      "                      mean       std\n",
      "Method                              \n",
      "brightness        0.064932  0.141538\n",
      "contrast          0.527448  0.492261\n",
      "defocus_blur      0.339945  0.407585\n",
      "fog               0.397061  0.480354\n",
      "frost             0.640226  0.474439\n",
      "gaussian_blur     0.292277  0.424510\n",
      "gaussian_noise    0.469957  0.498277\n",
      "glass_blur        0.211459  0.334700\n",
      "impulse_noise     0.590925  0.494465\n",
      "jpeg_compression  0.131869  0.191049\n",
      "motion_blur       0.299639  0.364775\n",
      "none              0.082256  0.179367\n",
      "pixelate          0.703352  0.354472\n",
      "shot_noise        0.432955  0.490291\n",
      "snow              0.794685  0.408848\n",
      "spatter           0.507812  0.502976\n",
      "speckle_noise     0.351097  0.469371\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create dataframe \n",
    "df = pd.DataFrame(data_table)\n",
    "df.columns = ['Sequence', 'Method', 'Level', 'Length Ratio', 'APE', 'RPE', 'Ave KP', 'Ave MP']\n",
    "with pd.ExcelWriter('orb_result_all.xlsx', mode='a', if_sheet_exists='replace') as writer:\n",
    "    df.to_excel(writer, sheet_name='image_perturbation_static_rgbd')\n",
    "\n",
    "# Filter by ratio of tracked lengths\n",
    "# df1 = df[df['Length Ratio']>0.8].groupby('Method')['APE'].mean()\n",
    "# df1 = df.groupby('Method')['Length Ratio'].mean()\n",
    "# df1 = df.groupby(['Method']).agg({'Length Ratio':['mean', 'std']})\n",
    "# with pd.ExcelWriter('orb_length_ratio.xlsx', mode='a', if_sheet_exists='replace') as writer1:\n",
    "#     df1.to_excel(writer1, sheet_name='image_perturbation_static_rgbd')\n",
    "# print(df1)\n",
    "df1 = df.groupby(['Method']).agg({'APE':['mean', 'std']})\n",
    "with pd.ExcelWriter('orb_ape.xlsx', mode='a', if_sheet_exists='replace') as writer1:\n",
    "    df1.to_excel(writer1, sheet_name='image_perturbation_static_rgbd')\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image perturbation (dynamic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       APE          \n",
      "                      mean       std\n",
      "Method                              \n",
      "brightness        0.065976  0.144607\n",
      "contrast          0.750639  0.461729\n",
      "defocus_blur      0.302988  0.434551\n",
      "fog               0.659048  0.475836\n",
      "frost             0.255967  0.459245\n",
      "gaussian_blur     0.051508  0.079546\n",
      "gaussian_noise    0.508131  0.525890\n",
      "glass_blur        0.167984  0.245440\n",
      "impulse_noise     0.755152  0.453372\n",
      "jpeg_compression  0.645180  0.491277\n",
      "motion_blur       0.279303  0.330419\n",
      "pixelate          0.755638  0.294402\n",
      "shot_noise        0.513253  0.520456\n",
      "snow              0.875567  0.351951\n",
      "spatter           0.752840  0.457676\n",
      "speckle_noise     0.262411  0.455280\n"
     ]
    }
   ],
   "source": [
    "def compute_stats(dir_est, traj_ref_dict, max_diff = 0.01): \n",
    "    # Save results, with list of ALL settings regardless of having results\n",
    "    data_table = []\n",
    "\n",
    "    methods = [\"motion_blur\", \"defocus_blur\", \"gaussian_blur\", \"glass_blur\",\n",
    "            \"gaussian_noise\", \"shot_noise\", \"impulse_noise\", \"speckle_noise\", \n",
    "            \"fog\", \"frost\", \"snow\", \"spatter\",\n",
    "            \"brightness\", \"contrast\", \"jpeg_compression\", \"pixelate\"]\n",
    "\n",
    "    for method in methods: \n",
    "        # for k in range(1, 6, 2): \n",
    "            # office \n",
    "            for n in range(5):\n",
    "                seq = \"office\" + str(n)\n",
    "                key = '_'.join([seq, method, 'rand'])\n",
    "                line = compute_single_stat(seq, method, 'rand', key, dir_est, traj_ref_dict, max_diff)\n",
    "                data_table.append(line)\n",
    "            \n",
    "            # room \n",
    "            for n in range(3):\n",
    "                seq = \"room\" + str(n)\n",
    "                key = '_'.join([seq, method,'rand'])\n",
    "                line = compute_single_stat(seq, method, 'rand', key, dir_est, traj_ref_dict, max_diff)\n",
    "                data_table.append(line)\n",
    "    \n",
    "    return data_table\n",
    "\n",
    "\n",
    "dir_est = \"/media/huanglab/HuangLab10TB/slam_team/sibo/results_replica/rgbd/rgbd1_dyn_image_perturbation/\"\n",
    "data_table = compute_stats(dir_est, traj_ref_dict)\n",
    "\n",
    "# Create dataframe \n",
    "df = pd.DataFrame(data_table)\n",
    "df.columns = ['Sequence', 'Method', 'Level', 'Length Ratio', 'APE', 'RPE', 'Ave KP', 'Ave MP']\n",
    "with pd.ExcelWriter('orb_result_all.xlsx', mode='a', if_sheet_exists='replace') as writer:\n",
    "    df.to_excel(writer, sheet_name='image_perturbation_dyn_rgbd')\n",
    "\n",
    "# Filter by ratio of tracked lengths\n",
    "# df1 = df[df['Length Ratio']>0.8].groupby('Method')['APE'].mean()\n",
    "# df1 = df.groupby('Method')['Length Ratio'].mean()\n",
    "# df1 = df.groupby(['Method']).agg({'Length Ratio':['mean', 'std']})\n",
    "# with pd.ExcelWriter('orb_length_ratio.xlsx', mode='a', if_sheet_exists='replace') as writer1:\n",
    "#     df1.to_excel(writer1, sheet_name='image_perturbation_dyn_rgbd')\n",
    "# print(df1)\n",
    "df1 = df.groupby(['Method']).agg({'APE':['mean', 'std']})\n",
    "with pd.ExcelWriter('orb_ape.xlsx', mode='a', if_sheet_exists='replace') as writer1:\n",
    "    df1.to_excel(writer1, sheet_name='image_perturbation_dyn_rgbd')\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faster motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Length Ratio          \n",
      "              mean       std\n",
      "Level                       \n",
      "r2        0.893777  0.080546\n",
      "r4        0.909299  0.048945\n",
      "r8        0.837443  0.114871\n"
     ]
    }
   ],
   "source": [
    "def compute_stats(dir_est, traj_ref_dict, max_diff = 0.01): \n",
    "    # Save results, with list of ALL settings regardless of having results\n",
    "    data_table = []\n",
    "\n",
    "    methods = [\"faster_motion\"]\n",
    "\n",
    "    for method in methods: \n",
    "        for k in [2, 4, 8]: \n",
    "            # office \n",
    "            for n in range(5):\n",
    "                seq = \"office\" + str(n)\n",
    "                key = '_'.join([seq, 'r' + str(k)])\n",
    "                line = compute_single_stat(seq, method, 'r' + str(k), key, dir_est, traj_ref_dict, max_diff)\n",
    "                data_table.append(line)\n",
    "            \n",
    "            # room \n",
    "            for n in range(3):\n",
    "                seq = \"room\" + str(n)\n",
    "                key = '_'.join([seq, 'r' + str(k)])\n",
    "                line = compute_single_stat(seq, method, 'r' + str(k), key, dir_est, traj_ref_dict, max_diff)\n",
    "                data_table.append(line)\n",
    "    \n",
    "    return data_table\n",
    "\n",
    "\n",
    "dir_est = \"/media/huanglab/HuangLab10TB/slam_team/sibo/results_replica/rgbd/rgbd1_faster_motion/\"\n",
    "data_table = compute_stats(dir_est, traj_ref_dict)\n",
    "\n",
    "# Create dataframe \n",
    "df = pd.DataFrame(data_table)\n",
    "df.columns = ['Sequence', 'Method', 'Level', 'Length Ratio', 'APE', 'RPE', 'Ave KP', 'Ave MP']\n",
    "with pd.ExcelWriter('orb_result_all.xlsx', mode='a', if_sheet_exists='replace') as writer:\n",
    "    df.to_excel(writer, sheet_name='faster_motion_rgbd')\n",
    "\n",
    "# Filter by ratio of tracked lengths\n",
    "# df1 = df[df['Length Ratio']>0.8].groupby('Method')['APE'].mean()\n",
    "# df1 = df.groupby('Level')['Length Ratio'].mean()\n",
    "df1 = df.groupby(['Level']).agg({'Length Ratio':['mean', 'std']})\n",
    "with pd.ExcelWriter('orb_length_ratio.xlsx', mode='a', if_sheet_exists='replace') as writer1:\n",
    "    df1.to_excel(writer1, sheet_name='faster_motion_rgbd')\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               APE          \n",
      "                              mean       std\n",
      "Method                                      \n",
      "depth_add_edge_erosion    0.807425  0.364686\n",
      "depth_add_gaussian_noise  0.802572  0.300749\n",
      "depth_add_random_mask     0.755583  0.396600\n",
      "depth_range               0.994002  0.282975\n"
     ]
    }
   ],
   "source": [
    "def compute_stats(dir_est, traj_ref_dict, max_diff = 0.01): \n",
    "    # Save results, with list of ALL settings regardless of having results\n",
    "    data_table = []\n",
    "\n",
    "    methods = [\"depth_add_gaussian_noise\", \"depth_add_edge_erosion\", \"depth_add_random_mask\", \"depth_range\"]\n",
    "\n",
    "    for method in methods: \n",
    "        for k in [3]: \n",
    "            # office \n",
    "            for n in range(5):\n",
    "                seq = \"office\" + str(n)\n",
    "                key = '_'.join([seq, method, str(k)])\n",
    "                line = compute_single_stat(seq, method, k, key, dir_est, traj_ref_dict, max_diff)\n",
    "                data_table.append(line)\n",
    "            \n",
    "            # room \n",
    "            for n in range(3):\n",
    "                seq = \"room\" + str(n)\n",
    "                key = '_'.join([seq, method, str(k)])\n",
    "                line = compute_single_stat(seq, method, k, key, dir_est, traj_ref_dict, max_diff)\n",
    "                data_table.append(line)\n",
    "    \n",
    "    return data_table\n",
    "\n",
    "\n",
    "dir_est = \"/media/huanglab/HuangLab10TB/slam_team/sibo/results_replica/rgbd/rgbd1_depth_perturbation/\"\n",
    "data_table = compute_stats(dir_est, traj_ref_dict)\n",
    "\n",
    "# Create dataframe \n",
    "df = pd.DataFrame(data_table)\n",
    "df.columns = ['Sequence', 'Method', 'Level', 'Length Ratio', 'APE', 'RPE', 'Ave KP', 'Ave MP']\n",
    "with pd.ExcelWriter('orb_result_all.xlsx', mode='a', if_sheet_exists='replace') as writer:\n",
    "    df.to_excel(writer, sheet_name='depth_perturbation')\n",
    "\n",
    "# Filter by ratio of tracked lengths\n",
    "# df1 = df[df['Length Ratio']>0.8].groupby('Method')['APE'].mean()\n",
    "# df1 = df.groupby('Method')['Length Ratio'].mean()\n",
    "# df1 = df.groupby(['Method']).agg({'Length Ratio':['mean', 'std']})\n",
    "# with pd.ExcelWriter('orb_length_ratio.xlsx', mode='a', if_sheet_exists='replace') as writer1:\n",
    "#     df1.to_excel(writer1, sheet_name='depth_perturbation')\n",
    "# print(df1)\n",
    "df1 = df.groupby(['Method']).agg({'APE':['mean', 'std']})\n",
    "with pd.ExcelWriter('orb_ape.xlsx', mode='a', if_sheet_exists='replace') as writer1:\n",
    "    df1.to_excel(writer1, sheet_name='depth_perturbation')\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensor misalignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Length Ratio          \n",
      "              mean       std\n",
      "Level                       \n",
      "k10       0.942307  0.050416\n",
      "k20       0.948122  0.041312\n",
      "k5        0.955365  0.039133\n"
     ]
    }
   ],
   "source": [
    "def compute_stats(dir_est, traj_ref_dict, max_diff = 0.01): \n",
    "    # Save results, with list of ALL settings regardless of having results\n",
    "    data_table = []\n",
    "\n",
    "    methods = [\"misalign\"]\n",
    "\n",
    "    for method in methods: \n",
    "        for k in [5, 10, 20]: \n",
    "            # office \n",
    "            for n in range(5):\n",
    "                seq = \"office\" + str(n)\n",
    "                key = '_'.join([seq, 'k' + str(k)])\n",
    "                line = compute_single_stat(seq, method, 'k' + str(k), key, dir_est, traj_ref_dict, max_diff)\n",
    "                data_table.append(line)\n",
    "            \n",
    "            # room \n",
    "            for n in range(3):\n",
    "                seq = \"room\" + str(n)\n",
    "                key = '_'.join([seq, 'k' + str(k)])\n",
    "                line = compute_single_stat(seq, method, 'k' + str(k), key, dir_est, traj_ref_dict, max_diff)\n",
    "                data_table.append(line)\n",
    "    \n",
    "    return data_table\n",
    "\n",
    "\n",
    "dir_est = \"/media/huanglab/HuangLab10TB/slam_team/sibo/results_replica/sensor_misalign/dynamic\"\n",
    "data_table = compute_stats(dir_est, traj_ref_dict)\n",
    "\n",
    "# Create dataframe \n",
    "df = pd.DataFrame(data_table)\n",
    "df.columns = ['Sequence', 'Method', 'Level', 'Length Ratio', 'APE', 'RPE', 'Ave KP', 'Ave MP']\n",
    "with pd.ExcelWriter('orb_result_all.xlsx', mode='a', if_sheet_exists='replace') as writer:\n",
    "    df.to_excel(writer, sheet_name='sensor_misalign_dynamic')\n",
    "\n",
    "# Filter by ratio of tracked lengths\n",
    "# df1 = df[df['Length Ratio']>0.8].groupby('Method')['APE'].mean()\n",
    "# df1 = df.groupby('Level')['Length Ratio'].mean()\n",
    "df1 = df.groupby(['Level']).agg({'Length Ratio':['mean', 'std']})\n",
    "with pd.ExcelWriter('orb_length_ratio.xlsx', mode='a', if_sheet_exists='replace') as writer1:\n",
    "    df1.to_excel(writer1, sheet_name='sensor_misalign_dynamic')\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trajectory perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Length Ratio          \n",
      "                     mean       std\n",
      "Rot Tran                           \n",
      "0   0            0.885372  0.066975\n",
      "    0dot0125     0.489365  0.106986\n",
      "    0dot025      0.246887  0.128577\n",
      "    0dot05       0.128486  0.091127\n",
      "1   0            0.661958  0.328845\n",
      "    0dot0125     0.339963  0.189277\n",
      "    0dot025      0.221513  0.156063\n",
      "    0dot05       0.120412  0.068644\n",
      "3   0            0.373553  0.329293\n",
      "    0dot0125     0.096124  0.154055\n",
      "    0dot025      0.087193  0.080761\n",
      "    0dot05       0.059375  0.055568\n",
      "5   0            0.413572  0.418438\n",
      "    0dot0125     0.154607  0.159983\n",
      "    0dot025      0.214462  0.111663\n",
      "    0dot05       0.143885  0.039416\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# compute stats of one given experiment\n",
    "def compute_single_stat(seq, method, k, key, dir_est, dir_ref, max_diff):\n",
    "    line = [seq, method, k, 0, 1, 1, -1, -1]\n",
    "\n",
    "    abs_path = os.path.join(dir_est, key + '.txt')\n",
    "    if not os.path.isfile(abs_path): \n",
    "        return line \n",
    "    if not os.path.getsize(abs_path):\n",
    "        return line\n",
    "\n",
    "    traj_est = file_interface.read_tum_trajectory_file(abs_path)\n",
    "    abs_path_ref = os.path.join(dir_ref, \"Replica_\" + key + \"_normal\", \"traj.txt\")\n",
    "    traj_ref = read_ref_to_tum(abs_path_ref, path_stamps)\n",
    "\n",
    "    if traj_est.num_poses < 3:\n",
    "        return line\n",
    "    path_length_ref = traj_ref.path_length\n",
    "    \n",
    "    # synchronize, align and scale\n",
    "    traj_ref, traj_est_aligned = sync.associate_trajectories(traj_ref, traj_est, max_diff)\n",
    "    traj_est_aligned.align(traj_ref, correct_scale=True, correct_only_scale=False)\n",
    "\n",
    "    # create metric relation and data\n",
    "    pose_relation = metrics.PoseRelation.translation_part\n",
    "    data = (traj_ref, traj_est_aligned)\n",
    "\n",
    "    # process APE\n",
    "    ape_metric = metrics.APE(pose_relation)\n",
    "    ape_metric.process_data(data)\n",
    "\n",
    "    ape_stat = ape_metric.get_statistic(metrics.StatisticsType.rmse)\n",
    "    line[3] = traj_est_aligned.path_length / path_length_ref\n",
    "    line[4] = ape_stat\n",
    "\n",
    "    # RPE\n",
    "    # synchronize, align and scale\n",
    "    traj_ref, traj_est_rpe = sync.associate_trajectories(traj_ref, traj_est, max_diff)\n",
    "\n",
    "    pose_relation = metrics.PoseRelation.rotation_angle_rad\n",
    "\n",
    "    # normal mode\n",
    "    delta = 1\n",
    "\n",
    "    # all pairs mode\n",
    "    all_pairs = False  # activate\n",
    "    data = (traj_ref, traj_est_rpe)\n",
    "\n",
    "    rpe_metric = metrics.RPE(pose_relation=pose_relation, delta=delta, all_pairs=all_pairs)\n",
    "    rpe_metric.process_data(data)\n",
    "\n",
    "    rpe_stat = rpe_metric.get_statistic(metrics.StatisticsType.rmse)\n",
    "    line[5] = rpe_stat\n",
    "\n",
    "\n",
    "    abs_path_feats = os.path.join(dir_est, 'keypoints', key + '_feats.txt')\n",
    "    if not os.path.isfile(abs_path_feats): \n",
    "        return line \n",
    "    if not os.path.getsize(abs_path_feats):\n",
    "        return line\n",
    "    \n",
    "    with open(abs_path_feats, 'r') as f: \n",
    "        ll = [int(l) for l in f]\n",
    "        if len(ll) == 2:\n",
    "            line[6:] = ll\n",
    "    \n",
    "    return line\n",
    "\n",
    "\n",
    "def compute_stats(dir_est, dir_ref, max_diff = 0.01): \n",
    "    # Save results, with list of ALL settings regardless of having results\n",
    "    data_table = []\n",
    "\n",
    "    for ri in [0, 1, 3, 5]: \n",
    "        for ti in [\"0\", \"0dot0125\", \"0dot025\", \"0dot05\"]: \n",
    "            # office \n",
    "            for n in range(5):\n",
    "                seq = \"office\" + str(n)\n",
    "                key = '_'.join([\"office\", str(n), 'rot', str(ri), 'tran', ti])\n",
    "                line = compute_single_stat(seq, ri, ti, key, dir_est, dir_ref, max_diff)\n",
    "                data_table.append(line)\n",
    "            \n",
    "            # room \n",
    "            for n in range(3):\n",
    "                seq = \"room\" + str(n)\n",
    "                key = '_'.join([\"room\", str(n), 'rot', str(ri), 'tran', ti])\n",
    "                line = compute_single_stat(seq, ri, ti, key, dir_est, dir_ref, max_diff)\n",
    "                data_table.append(line)\n",
    "    \n",
    "    return data_table\n",
    "\n",
    "\n",
    "dir_ref = \"/media/huanglab/HuangLab10TB/slam_team/dataset/Replica-Dataset-Traj-Perturbed_simple/\"\n",
    "dir_est = \"/media/huanglab/HuangLab10TB/slam_team/sibo/results_replica/perturb_trajectory/rgbd1/\"\n",
    "data_table = compute_stats(dir_est, dir_ref)\n",
    "\n",
    "# Create dataframe \n",
    "df = pd.DataFrame(data_table)\n",
    "df.columns = ['Sequence', 'Rot', 'Tran', 'Length Ratio', 'APE', 'RPE', 'Ave KP', 'Ave MP']\n",
    "with pd.ExcelWriter('orb_result_all.xlsx', mode='a', if_sheet_exists='replace') as writer:\n",
    "    df.to_excel(writer, sheet_name='trajectory_perturbation_rgbd')\n",
    "\n",
    "# Filter by ratio of tracked lengths\n",
    "# df1 = df[df['Length Ratio']>0.8].groupby('Method')['APE'].mean()\n",
    "# df1 = df.groupby(['Rot', 'Tran'])['Length Ratio'].mean()\n",
    "df1 = df.groupby(['Rot', 'Tran']).agg({'Length Ratio':['mean', 'std']})\n",
    "with pd.ExcelWriter('orb_length_ratio.xlsx', mode='a', if_sheet_exists='replace') as writer1:\n",
    "    df1.to_excel(writer1, sheet_name='trajectory_perturbation_rgbd')\n",
    "print(df1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
